{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "587a81eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from scipy.sparse import hstack\n",
    "from collections import defaultdict\n",
    "from typing import Tuple\n",
    "\n",
    "import pickle as pkl\n",
    "import os\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05f28931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>aisle</th>\n",
       "      <th>department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Chocolate Sandwich Cookies</td>\n",
       "      <td>cookies cakes</td>\n",
       "      <td>snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>All-Seasons Salt</td>\n",
       "      <td>spices seasonings</td>\n",
       "      <td>pantry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Robust Golden Unsweetened Oolong Tea</td>\n",
       "      <td>tea</td>\n",
       "      <td>beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Smart Ones Classic Favorites Mini Rigatoni Wit...</td>\n",
       "      <td>frozen meals</td>\n",
       "      <td>frozen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Green Chile Anytime Sauce</td>\n",
       "      <td>marinades meat preparation</td>\n",
       "      <td>pantry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49683</th>\n",
       "      <td>49684</td>\n",
       "      <td>Vodka, Triple Distilled, Twist of Vanilla</td>\n",
       "      <td>spirits</td>\n",
       "      <td>alcohol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49684</th>\n",
       "      <td>49685</td>\n",
       "      <td>En Croute Roast Hazelnut Cranberry</td>\n",
       "      <td>frozen vegan vegetarian</td>\n",
       "      <td>frozen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49685</th>\n",
       "      <td>49686</td>\n",
       "      <td>Artisan Baguette</td>\n",
       "      <td>bread</td>\n",
       "      <td>bakery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49686</th>\n",
       "      <td>49687</td>\n",
       "      <td>Smartblend Healthy Metabolism Dry Cat Food</td>\n",
       "      <td>cat food care</td>\n",
       "      <td>pets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49687</th>\n",
       "      <td>49688</td>\n",
       "      <td>Fresh Foaming Cleanser</td>\n",
       "      <td>facial care</td>\n",
       "      <td>personal care</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49688 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_id                                       product_name  \\\n",
       "0               1                         Chocolate Sandwich Cookies   \n",
       "1               2                                   All-Seasons Salt   \n",
       "2               3               Robust Golden Unsweetened Oolong Tea   \n",
       "3               4  Smart Ones Classic Favorites Mini Rigatoni Wit...   \n",
       "4               5                          Green Chile Anytime Sauce   \n",
       "...           ...                                                ...   \n",
       "49683       49684          Vodka, Triple Distilled, Twist of Vanilla   \n",
       "49684       49685                 En Croute Roast Hazelnut Cranberry   \n",
       "49685       49686                                   Artisan Baguette   \n",
       "49686       49687         Smartblend Healthy Metabolism Dry Cat Food   \n",
       "49687       49688                             Fresh Foaming Cleanser   \n",
       "\n",
       "                            aisle     department  \n",
       "0                   cookies cakes         snacks  \n",
       "1               spices seasonings         pantry  \n",
       "2                             tea      beverages  \n",
       "3                    frozen meals         frozen  \n",
       "4      marinades meat preparation         pantry  \n",
       "...                           ...            ...  \n",
       "49683                     spirits        alcohol  \n",
       "49684     frozen vegan vegetarian         frozen  \n",
       "49685                       bread         bakery  \n",
       "49686               cat food care           pets  \n",
       "49687                 facial care  personal care  \n",
       "\n",
       "[49688 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_detailed_products(verbose=False):\n",
    "    if verbose == True: print('(Data Collection 0/2) Read relevant csv files ...')\n",
    "    aisles = pd.read_csv('../instacart/aisles.csv')\n",
    "    departments = pd.read_csv('../instacart/departments.csv')\n",
    "    products = pd.read_csv('../instacart/products.csv')\n",
    "\n",
    "    if verbose == True: print('(Data Collection 1/2) Merging csv files and drop irrelevant columns ...')\n",
    "    detailed_products = products.merge(aisles, on='aisle_id', how='inner')\n",
    "    detailed_products = detailed_products.merge(departments, on='department_id', how='inner')\n",
    "    detailed_products = detailed_products.drop(columns=['aisle_id','department_id'])\n",
    "\n",
    "    if verbose == True: print('(Data Collection 2/2) Dataset successfully prepared ...')\n",
    "    return detailed_products\n",
    "\n",
    "detailed_products = get_detailed_products()\n",
    "detailed_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38446f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def clean_text_feature(data : pd.DataFrame, lowercase=True, stopword=True, lemma=False, stem=False, punc=True, number=True, url=False, email=False):\n",
    "\n",
    "    punctuation = string.punctuation\n",
    "    stopwordlist = stopwords.words('english')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "    def remove_urls(text):\n",
    "        return re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
    "\n",
    "    def remove_emails(text):\n",
    "        return re.sub(r'\\S+@\\S+', '', text)\n",
    "\n",
    "    def text_cleaning(sentence):\n",
    "        if not isinstance(sentence, str): return \"\"\n",
    "        if lowercase:\n",
    "            sentence = sentence.lower()\n",
    "        if url: \n",
    "            sentence = remove_urls(sentence)\n",
    "        if email: \n",
    "            sentence = remove_emails(sentence)\n",
    "        words = word_tokenize(sentence)\n",
    "        if punc: \n",
    "            words = [word for word in words if word not in punctuation]\n",
    "        if stopword: \n",
    "            words = [word for word in words if word not in stopwordlist]\n",
    "        if number: \n",
    "            words = [word for word in words if word.isalpha()]\n",
    "        if lemma:\n",
    "            pos_tags = pos_tag(words)\n",
    "            words = [lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in pos_tags]\n",
    "        if stem:\n",
    "            words = [stemmer.stem(word) for word in words]\n",
    "        return \" \".join(words)\n",
    "\n",
    "    df = data.copy()\n",
    "    df[df.columns[0]] = df[df.columns[0]].apply(lambda x: text_cleaning(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3350dd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(dataset : pd.DataFrame, sparse=False, verbose=False):\n",
    "    if verbose == True: print(f\"(Encode Features 0/3) Determine model filepath ...\")\n",
    "    data = dataset.copy()\n",
    "    column = dataset.columns[0]\n",
    "    model_path = f'../models/{column}_onehotencoder.pkl'\n",
    "\n",
    "    if os.path.exists(model_path):\n",
    "        if verbose == True: print(f\"(Encode Features 1/3) Loading existing encoder from {model_path}...\")\n",
    "        encoder = pd.read_pickle(model_path)\n",
    "    else:\n",
    "        if verbose == True: print(f\"(Encode Features 1/3) Training a new aisle encoder and saving it to {model_path}...\")\n",
    "        encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=sparse)\n",
    "        encoder.fit(data)\n",
    "        pd.to_pickle(encoder, model_path)\n",
    "        \n",
    "    if verbose == True: print(f\"(Encode Features 2/3) Encode relevant features...\")\n",
    "    dataset_encoded = encoder.transform(data)\n",
    "    returned = dataset_encoded if sparse else pd.DataFrame(dataset_encoded, columns=encoder.get_feature_names_out([column]), index=dataset.index)\n",
    "    if verbose == True: print(f\"(Encode Features 3/3) Feature Encoding finished...\")\n",
    "    return returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ef25d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_to_tfidf(dataset: pd.DataFrame, sparse=False, verbose=False):\n",
    "    if verbose == True: print(f\"(Text Feature Extraction 0/3) Determine model filepath ...\")\n",
    "    column = dataset.columns[0]\n",
    "    data = dataset[[column]].copy()\n",
    "    model_path = f'../models/{column}_tfidf_vectorizer.pkl'\n",
    "\n",
    "    if os.path.exists(model_path):\n",
    "        if verbose == True: print(f\"(Text Feature Extraction 1/3) Loading existing vectorizer from {model_path} ...\")\n",
    "        with open(model_path, 'rb') as file:\n",
    "            vectorizer = pkl.load(file)\n",
    "    else:\n",
    "        if verbose == True: print(f\"(Text Feature Extraction 1/3) Training new TF-IDF vectorizer and saving it to {model_path} ...\")\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        vectorizer.fit(data[column])\n",
    "        with open(model_path, 'wb') as file:\n",
    "            pkl.dump(vectorizer, file)\n",
    "\n",
    "    if verbose == True: print(f\"(Text Feature Extraction 2/3) Transform text data into TF-IDF numeric features ...\")\n",
    "    tfidf_matrix = vectorizer.transform(data[column])\n",
    "\n",
    "    if verbose == True: print(f\"(Text Feature Extraction 3/3) Feature Extraction Done ...\")\n",
    "    if sparse:\n",
    "        return tfidf_matrix, vectorizer\n",
    "    else:\n",
    "        return pd.DataFrame(\n",
    "            tfidf_matrix.toarray(),\n",
    "            columns=vectorizer.get_feature_names_out([column]),\n",
    "            index=data.index\n",
    "        ), vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68d13053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id\n",
       "0           1\n",
       "1           2\n",
       "2           3\n",
       "3           4\n",
       "4           5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_features(userproducts : pd.DataFrame, verbose=False):\n",
    "    tfidf_matrix, _ = raw_to_tfidf(userproducts[['product_name']], sparse=True, verbose=verbose)\n",
    "    encoded_aisle = encode(userproducts[['aisle']], sparse=True, verbose=verbose)\n",
    "    encoded_department = encode(userproducts[['department']], sparse=True, verbose=verbose)\n",
    "    id_map = userproducts[['product_id']]\n",
    "    return hstack([tfidf_matrix, encoded_aisle, encoded_department]), id_map\n",
    "\n",
    "features, id_map = extract_features(detailed_products)\n",
    "id_map.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fd11983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(features) -> NearestNeighbors:\n",
    "    print(f\"(Model Training 0/1) Train NN model in progress ...\")\n",
    "    model = NearestNeighbors(n_neighbors=100, metric='cosine', n_jobs=4)\n",
    "    model.fit(features)\n",
    "    print(f\"(Model Training 1/1) Train NN model finished ...\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "552353bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(userproducts):\n",
    "    trainset, testset = train_test_split(userproducts, test_size=0.3, random_state=42, stratify=userproducts['department_id'])\n",
    "    return trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35a3d4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_userproducts():\n",
    "    print('(Get UserProducts 0/5) Reading and merging csv dataset ...')\n",
    "    orderproducts = pd.read_csv('../instacart/order_products__train.csv')\n",
    "    orders = pd.read_csv('../instacart/orders.csv')\n",
    "\n",
    "    print('(Get UserProducts 1/5) Filter to only include orders which is in train and test set...')\n",
    "    orders = orders[orders['eval_set'].isin(['train','test'])]\n",
    "\n",
    "    print('(Get UserProducts 2/5) Merge orderproducts and orders, then remove irrelevant columns...')\n",
    "    userproducts = orderproducts.merge(orders, on='order_id', how='inner')\n",
    "    userproducts = userproducts[['product_id','user_id','reordered']]\n",
    "\n",
    "    print('(Get UserProducts 3/5) Remove user which only occur once to prevent error during testing...')\n",
    "    uid_counts = userproducts['user_id'].value_counts()\n",
    "    valid_uids = uid_counts[uid_counts > 1].index\n",
    "    userproducts = userproducts[userproducts['user_id'].isin(valid_uids)]\n",
    "\n",
    "    print('(Get UserProducts 4/5) Remove duplicated data and missing value if exists...')\n",
    "    userproducts = userproducts.dropna(inplace=False)\n",
    "    userproducts = userproducts.drop_duplicates(inplace=False)\n",
    "\n",
    "    print('(Get UserProducts 5/5) Get UserProducts process is done!')\n",
    "    return userproducts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26a76191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(state=\"evaluation\") -> Tuple[NearestNeighbors | None, pd.DataFrame | None]:\n",
    "\n",
    "    if not (state == \"evaluation\" or state == \"production\"):\n",
    "        print(f\"Invalid state...\")\n",
    "        return None, None\n",
    "    \n",
    "    model_filename = f'../models/nn_model_{state}.pkl'\n",
    "    iidmap_filename = f\"../models/iid_mapping_{state}.pkl\"\n",
    "\n",
    "    if os.path.exists(model_filename) and os.path.exists(iidmap_filename):\n",
    "        print('Model already exist, currently load it ...')\n",
    "        with open(model_filename,'rb') as f:\n",
    "            model = pkl.load(f)\n",
    "        with open(iidmap_filename,'rb') as f:\n",
    "            iid_map = pkl.load(f)\n",
    "\n",
    "        print('Model successfully loaded ...')\n",
    "        return model, iid_map\n",
    "    else:\n",
    "        print('Model doesnt exist yet. Train new model ...')\n",
    "        detailed_products = get_detailed_products()\n",
    "        preprocessed_products, iid_map = extract_features(detailed_products, verbose=True)\n",
    "        model = train_model(preprocessed_products)\n",
    "\n",
    "        print('Saving trained model ...')\n",
    "        with open(model_filename,'wb') as f:\n",
    "            pkl.dump(model, f)\n",
    "        with open(iidmap_filename,'wb') as f:\n",
    "            pkl.dump(iid_map, f)\n",
    "\n",
    "        print('Model successfully loaded ...')\n",
    "        return model, iid_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd161db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   product_id                product_name          aisle department\n",
      "0           1  Chocolate Sandwich Cookies  cookies cakes     snacks \n",
      "\n",
      "Model already exist, currently load it ...\n",
      "Model successfully loaded ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>avg_distance</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>aisle</th>\n",
       "      <th>department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>Chocolate Sandwich Cookies</td>\n",
       "      <td>cookies cakes</td>\n",
       "      <td>snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23931</td>\n",
       "      <td>0.060354</td>\n",
       "      <td>23932</td>\n",
       "      <td>Chocolate Creme Sandwich Cookies</td>\n",
       "      <td>cookies cakes</td>\n",
       "      <td>snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12480</td>\n",
       "      <td>0.080673</td>\n",
       "      <td>12481</td>\n",
       "      <td>Oreo Chocolate Sandwich Cookies</td>\n",
       "      <td>cookies cakes</td>\n",
       "      <td>snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9293</td>\n",
       "      <td>0.085177</td>\n",
       "      <td>9294</td>\n",
       "      <td>Reduced Fat Chocolate Sandwich Cookies</td>\n",
       "      <td>cookies cakes</td>\n",
       "      <td>snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22413</td>\n",
       "      <td>0.088592</td>\n",
       "      <td>22414</td>\n",
       "      <td>Chocolate Mint Creme Sandwich Cookies</td>\n",
       "      <td>cookies cakes</td>\n",
       "      <td>snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1623</td>\n",
       "      <td>0.089686</td>\n",
       "      <td>1624</td>\n",
       "      <td>Chocolate Cookies</td>\n",
       "      <td>cookies cakes</td>\n",
       "      <td>snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11638</td>\n",
       "      <td>0.090158</td>\n",
       "      <td>11639</td>\n",
       "      <td>Chocolate Berry Creme Sandwich Cookies</td>\n",
       "      <td>cookies cakes</td>\n",
       "      <td>snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4690</td>\n",
       "      <td>0.096140</td>\n",
       "      <td>4691</td>\n",
       "      <td>Creme Sandwich Cookies</td>\n",
       "      <td>cookies cakes</td>\n",
       "      <td>snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>33321</td>\n",
       "      <td>0.104094</td>\n",
       "      <td>33322</td>\n",
       "      <td>Chocolate Peanut Butter Creme Sandwich Cookies</td>\n",
       "      <td>cookies cakes</td>\n",
       "      <td>snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15758</td>\n",
       "      <td>0.107325</td>\n",
       "      <td>15759</td>\n",
       "      <td>Peanut Butter Sandwich Cookies</td>\n",
       "      <td>cookies cakes</td>\n",
       "      <td>snacks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  avg_distance  product_id  \\\n",
       "0      0      0.000000           1   \n",
       "1  23931      0.060354       23932   \n",
       "2  12480      0.080673       12481   \n",
       "3   9293      0.085177        9294   \n",
       "4  22413      0.088592       22414   \n",
       "5   1623      0.089686        1624   \n",
       "6  11638      0.090158       11639   \n",
       "7   4690      0.096140        4691   \n",
       "8  33321      0.104094       33322   \n",
       "9  15758      0.107325       15759   \n",
       "\n",
       "                                     product_name          aisle department  \n",
       "0                      Chocolate Sandwich Cookies  cookies cakes     snacks  \n",
       "1                Chocolate Creme Sandwich Cookies  cookies cakes     snacks  \n",
       "2                 Oreo Chocolate Sandwich Cookies  cookies cakes     snacks  \n",
       "3          Reduced Fat Chocolate Sandwich Cookies  cookies cakes     snacks  \n",
       "4           Chocolate Mint Creme Sandwich Cookies  cookies cakes     snacks  \n",
       "5                               Chocolate Cookies  cookies cakes     snacks  \n",
       "6          Chocolate Berry Creme Sandwich Cookies  cookies cakes     snacks  \n",
       "7                          Creme Sandwich Cookies  cookies cakes     snacks  \n",
       "8  Chocolate Peanut Butter Creme Sandwich Cookies  cookies cakes     snacks  \n",
       "9                  Peanut Butter Sandwich Cookies  cookies cakes     snacks  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recommend(products, product_mapping, model):\n",
    "    detailed_products = get_detailed_products()\n",
    "    preprocessed_products, _ = extract_features(products)\n",
    "    tally = defaultdict(list)\n",
    "    for i in range(preprocessed_products.shape[0]):\n",
    "        product_vector = preprocessed_products[i].reshape(1, -1)\n",
    "        distances, indices = model.kneighbors(product_vector, n_neighbors=10)\n",
    "        for dist, idx in zip(distances[0], indices[0]):\n",
    "            tally[idx].append(dist)\n",
    "\n",
    "    avg_distances = [(idx, sum(dists) / len(dists)) for idx, dists in tally.items()]\n",
    "    sorted_indices = sorted(avg_distances, key=lambda x: x[1])\n",
    "    recommended_ids = [product_mapping.iloc[idx]['product_id'] for idx, _ in sorted_indices]\n",
    "    recommended_products = detailed_products.set_index('product_id').loc[recommended_ids].reset_index()\n",
    "\n",
    "    result_df = pd.DataFrame(sorted_indices, columns=['index', 'avg_distance'])\n",
    "    result_df['product_id'] = result_df['index'].apply(lambda i: product_mapping.iloc[i]['product_id'])\n",
    "    final = result_df.merge(recommended_products, on='product_id')\n",
    "    return final\n",
    "\n",
    "test_products = detailed_products.iloc[[0]]\n",
    "print(test_products, '\\n')\n",
    "\n",
    "model, iid_map = load_model(state=\"production\")\n",
    "recommended_products = recommend(test_products, iid_map, model)\n",
    "recommended_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0e42699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1217, 18534, 12720, 4374, 43352, 16797}\n",
      "[(22282, 0.0), (11210, 0.0), (21137, 0.026766753906078744), (21879, 0.03152756532181167), (44177, 0.03152756532181167), (49439, 0.04251893524461359), (1890, 0.04251893524461359), (23410, 0.04750438821797354), (12149, 0.05072550412502874), (5782, 0.054216001300095185), (8066, 0.0554437542875581), (29176, 0.05608980263797614), (20051, 0.059279972348458054), (25487, 0.06092123205455979), (14999, 0.06092123205455979), (12709, 0.06213714574206319), (25097, 0.06355862507039722), (31654, 0.06535775915281938), (20247, 0.0679367748363433), (5262, 0.06795048241753543), (46654, 0.06908551095661086), (35921, 0.06908551095661086), (32684, 0.06908551095661086), (36550, 0.07310659969765143), (49478, 0.08119335695720187), (11390, 0.08183237375093677), (34791, 0.08204818980055872), (13949, 0.08206524546496852), (44025, 0.08465249783707285), (23341, 0.08501544047751963), (35595, 0.09124626784248435), (36186, 0.09124626784248435), (46620, 0.09390860936033518), (29628, 0.09468266809885706), (46636, 0.09474668095070404), (3471, 0.09486581395498672), (43209, 0.09492279286513017), (23543, 0.09566902095192464), (1330, 0.09746519216622018), (29034, 0.09777534771409147), (34234, 0.09811965136950418), (34467, 0.09818866686434002), (21868, 0.10185405869376196), (2210, 0.10217445063682007)]\n"
     ]
    }
   ],
   "source": [
    "def load_nn_model_and_mapping():\n",
    "    with open('../models/nn_model_production.pkl', 'rb') as f:\n",
    "        model = pkl.load(f)\n",
    "    with open('../models/iid_mapping_production.pkl', 'rb') as f:\n",
    "        product_mapping = pkl.load(f)\n",
    "    return model, product_mapping\n",
    "\n",
    "def get_userproduct_ids(user_id=17):\n",
    "    orderproducts = pd.read_csv('../instacart/order_products__train.csv')\n",
    "    orders = pd.read_csv('../instacart/orders.csv')\n",
    "    userorders = orders[orders['user_id'].isin([user_id])]['order_id']\n",
    "    userproducts = set(orderproducts[orderproducts['order_id'].isin(userorders)]['product_id'])\n",
    "    return userproducts\n",
    "\n",
    "def get_detailed_products():\n",
    "    aisles = pd.read_csv('../instacart/aisles.csv')\n",
    "    departments = pd.read_csv('../instacart/departments.csv')\n",
    "    products = pd.read_csv('../instacart/products.csv')\n",
    "    detailed_products = products.merge(aisles, on='aisle_id', how='inner')\n",
    "    detailed_products = detailed_products.merge(departments, on='department_id', how='inner')\n",
    "    detailed_products = detailed_products.drop(columns=['aisle_id','department_id'])\n",
    "    return detailed_products\n",
    "\n",
    "def recommendNN(user_id=17, top_n=50):\n",
    "    detailed_products = get_detailed_products()\n",
    "    userproduct_ids = get_userproduct_ids(user_id) # real product_id\n",
    "    products = detailed_products[detailed_products['product_id'].isin(userproduct_ids)]\n",
    "    model, product_mapping = load_nn_model_and_mapping()\n",
    "    \n",
    "    preprocessed_products, _ = extract_features(products)\n",
    "    tally = defaultdict(list)\n",
    "    for i in range(preprocessed_products.shape[0]):\n",
    "        product_vector = preprocessed_products[i].reshape(1, -1)\n",
    "        distances, indices = model.kneighbors(product_vector, n_neighbors=top_n)\n",
    "        for dist, idx in zip(distances[0], indices[0]):\n",
    "            tally[idx].append(dist)\n",
    "\n",
    "    avg_distances = [(idx, sum(dists) / len(dists)) for idx, dists in tally.items()] # innermap idx\n",
    "    sorted_indices = sorted(avg_distances, key=lambda x: x[1])[:top_n]\n",
    "    recommended_ids = [(product_mapping.iloc[idx]['product_id'], score) for idx, score in sorted_indices]\n",
    "    recommended_ids = [(idx, score) for idx, score in recommended_ids if idx not in userproduct_ids]\n",
    "\n",
    "    print(userproduct_ids)\n",
    "    return recommended_ids\n",
    "\n",
    "recommendation = recommendNN(user_id=17)\n",
    "print(recommendation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
